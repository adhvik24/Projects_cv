{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d8f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae3033bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Some hyperparameters and paths\n",
    "\n",
    "Device = 'cuda:0' if torch.cuda.is_available() else \"cpu\"\n",
    "train_r = \"/home/adhvik/Downloads/Adhvik/courses/summer/impl/FLIR_ADAS_1_3/train/RGB\"\n",
    "train_t = \"/home/adhvik/Downloads/Adhvik/courses/summer/impl/FLIR_ADAS_1_3/train/thermal_8_bit\"\n",
    "val_r = \"/home/adhvik/Downloads/Adhvik/courses/summer/impl/FLIR_ADAS_1_3/val/RGB\"\n",
    "val_t = \"/home/adhvik/Downloads/Adhvik/courses/summer/impl/FLIR_ADAS_1_3/val/thermal_8_bit\"\n",
    "lr_g = 3e-4\n",
    "lr_d = 3e-4\n",
    "batch_size = 16\n",
    "num_workers = 2\n",
    "num_epoch = 5\n",
    "lamda = 10\n",
    "\n",
    "print(Device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a167ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "#         A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
    "        A.Resize(width=256, height=256),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_2 = A.Compose(\n",
    "    [A.Resize(width=2*256, height=2*256), ],\n",
    "    additional_targets={\"image\": \"image0\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f04834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and Input data prep..\n",
    "class pairing_data(Dataset):\n",
    "    def __init__(self, par_dir_rgb, par_dir_th):\n",
    "        super(pairing_data, self).__init__()\n",
    "        self.rgb = par_dir_rgb\n",
    "        self.th = par_dir_th\n",
    "        self.files_rgb = os.listdir(self.rgb)\n",
    "        self.n = len(self.files_rgb)\n",
    "        self.files_th = []\n",
    "        jpg = ['jpg']*(self.n)\n",
    "        zip_object = zip(self.files_rgb, jpg)\n",
    "        for list1_i, list2_i in zip_object:\n",
    "            self.files_th.append(list1_i.replace(list2_i, 'jpeg'))\n",
    "        # self.files_th = os.listdir(self.th)\n",
    "\n",
    "    def __len__(self):\n",
    "        lrgb = len(self.files_rgb)\n",
    "        return lrgb\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        r_file = self.files_rgb[index]\n",
    "        t_file = self.files_th[index]\n",
    "        r_path = os.path.join(self.rgb, r_file)\n",
    "        t_path = os.path.join(self.th, t_file)\n",
    "        inp = np.array(Image.open(r_path))\n",
    "        out = np.array(Image.open(t_path))\n",
    "\n",
    "        mod = transform_2(image=inp, image0=out)\n",
    "        inp = mod[\"image\"]\n",
    "        out = mod[\"image0\"]\n",
    "\n",
    "        inp = transform(image=inp)[\"image\"]\n",
    "        out = transform(image=out)[\"image\"]\n",
    "\n",
    "        return inp, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1dddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, inp, out, stride=2, kernel_size=4):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(inp, out, stride, kernel_size,\n",
    "                      bias=False, padding=1, padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layer(x)\n",
    "\n",
    "\n",
    "class CNNB(nn.Module):\n",
    "    def __init__(self, inp, out, stride=2, kernel_size=4):\n",
    "        super(CNNB, self).__init__()\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(inp, out, stride, kernel_size, padding=1,\n",
    "                      bias=False, padding_mode='reflect'),\n",
    "            nn.BatchNorm2d(out),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layer1(x)\n",
    "\n",
    "    \n",
    "\n",
    "class unet_block(nn.Module):\n",
    "    def __init__(self, inp, out, dir='down', act_fn=\"ReLU\", drop=False):\n",
    "        super(unet_block, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(inp, out, 4, 2, 1, bias=False, padding_mode='reflect') if dir == 'down'\n",
    "            else\n",
    "            nn.ConvTranspose2d(inp, out, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out),\n",
    "            nn.ReLU() if act_fn == 'ReLU' else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.drop = drop\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dir = dir\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61ebb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Disc(nn.Module):\n",
    "    def __init__(self, inp=3, feature_dim=[64, 128, 256, 512]):\n",
    "        super(Disc, self).__init__()\n",
    "        convlayers = []\n",
    "        input = feature_dim[0]\n",
    "        convlayers.append(CNN(inp+1, input, 4, 2),)\n",
    "        for feature in feature_dim[1:]:\n",
    "            convlayers.append(\n",
    "                CNNB(input, feature, 4, 1 if feature == feature_dim[-1] else 2))\n",
    "            input = feature\n",
    "        convlayers.append(nn.Conv2d(input, 1, kernel_size=4,\n",
    "                          stride=1, padding=1, padding_mode='reflect'),)\n",
    "        convlayers.append(nn.Sigmoid())\n",
    "        self.model = nn.Sequential(*convlayers)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf3e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gen(nn.Module):\n",
    "    def __init__(self, inp=3, feature_dim=64):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Conv2d(inp, feature_dim, 4, 2, 1, padding_mode='reflect'),\n",
    "                                nn.LeakyReLU(0.2))\n",
    "        self.l2 = unet_block(\n",
    "            feature_dim, feature_dim*2, dir='down', act_fn='LReLU', drop=False)\n",
    "        self.l3 = unet_block(\n",
    "            feature_dim*2, feature_dim*4, dir='down', act_fn='LReLU', drop=False)\n",
    "        self.l4 = unet_block(\n",
    "            feature_dim*4, feature_dim*8, dir='down', act_fn='LReLU', drop=False)\n",
    "        self.l5 = unet_block(\n",
    "            feature_dim*8, feature_dim*8, dir='down', act_fn='LReLU', drop=False)\n",
    "        self.l6 = unet_block(\n",
    "            feature_dim*8, feature_dim*8, dir='down', act_fn='LReLU', drop=False)\n",
    "        self.l7 = unet_block(\n",
    "            feature_dim*8, feature_dim*8, dir='down', act_fn='LReLU', drop=False)\n",
    "\n",
    "        self.ul = nn.Sequential(nn.Conv2d(feature_dim*8, feature_dim*8, 4, 2, 1),\n",
    "                                nn.ReLU()\n",
    "                                )\n",
    "\n",
    "        self.l11 = unet_block(\n",
    "            feature_dim*8, feature_dim*8, dir='up', act_fn='ReLU', drop=True)\n",
    "        self.l12 = unet_block(\n",
    "            feature_dim*8*2, feature_dim*8, dir='up', act_fn='ReLU', drop=True)\n",
    "\n",
    "        self.l13 = unet_block(\n",
    "            feature_dim*8*2, feature_dim*8, dir='up', act_fn='ReLU', drop=True)\n",
    "\n",
    "        self.l14 = unet_block(\n",
    "            feature_dim*8*2, feature_dim*8, dir='up', act_fn='ReLU', drop=False)\n",
    "\n",
    "        self.l15 = unet_block(\n",
    "            feature_dim*8*2, feature_dim*4, dir='up', act_fn='ReLU', drop=False)\n",
    "\n",
    "        self.l16 = unet_block(\n",
    "            feature_dim*8, feature_dim*2, dir='up', act_fn='ReLU', drop=False)\n",
    "\n",
    "        self.l17 = unet_block(\n",
    "            feature_dim*4, feature_dim, dir='up', act_fn='ReLU', drop=False)\n",
    "\n",
    "        self.map_ = nn.Sequential(\n",
    "            nn.ConvTranspose2d(feature_dim*2, 1, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer1 = self.l1(x)\n",
    "        layer2 = self.l2(layer1)\n",
    "        layer3 = self.l3(layer2)\n",
    "        layer4 = self.l4(layer3)\n",
    "        layer5 = self.l5(layer4)\n",
    "        layer6 = self.l6(layer5)\n",
    "        layer7 = self.l7(layer6)\n",
    "\n",
    "        b_layer = self.ul(layer7)\n",
    "\n",
    "        layer11 = self.l11(b_layer)\n",
    "        layer22 = self.l12(torch.cat([layer11, layer7], dim=1))\n",
    "        layer33 = self.l13(torch.cat([layer22, layer6], dim=1))\n",
    "        layer44 = self.l14(torch.cat([layer33, layer5], dim=1))\n",
    "        layer55 = self.l15(torch.cat([layer44, layer4], dim=1))\n",
    "        layer66 = self.l16(torch.cat([layer55, layer3], dim=1))\n",
    "        layer77 = self.l17(torch.cat([layer66, layer2], dim=1))\n",
    "\n",
    "        map_layer = self.map_(torch.cat([layer77, layer1], dim=1))\n",
    "\n",
    "        return map_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8088baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Disc(inp=3).to(Device)\n",
    "gen = Gen(inp=3, feature_dim=64).to(Device)\n",
    "opt_disc = optim.Adam(\n",
    "    disc.parameters(), lr=lr_d, betas=(0.5, 0.999),)\n",
    "opt_gen = optim.Adam(\n",
    "    gen.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "BCE = nn.BCEWithLogitsLoss()\n",
    "L1_LOSS = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dcf72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pairing_data(train_r,train_t)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "val_dataset = pairing_data(val_r,val_t)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the gen and disc\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print('epoch: ',epoch+1)\n",
    "    for idx, (x, y) in enumerate(tqdm(train_loader,leave = True)):\n",
    "        if(idx<10):\n",
    "            x = x.float()/255\n",
    "            y = y.float()/255\n",
    "            x = x.to(Device)\n",
    "            y = y.to(Device)\n",
    "            # Training disc\n",
    "            y_fake = gen(x)\n",
    "            D_real = disc(x, y)\n",
    "            D_fake = disc(x, y_fake.detach())\n",
    "        \n",
    "            opt_disc.zero_grad()\n",
    "            D_real_loss = BCE(D_real, torch.ones_like(D_real))\n",
    "            D_fake_loss = BCE(D_fake, torch.zeros_like(D_fake))\n",
    "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
    "            D_loss.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "            \n",
    "            # Training gen\n",
    "            D_fake = disc(x, y_fake)\n",
    "            \n",
    "            opt_gen.zero_grad()\n",
    "            G_fake_loss = BCE(D_fake, torch.ones_like(D_fake))\n",
    "            L1 = L1_LOSS(y_fake, y) * lamda\n",
    "            G_loss = G_fake_loss + L1\n",
    "            G_loss.backward()\n",
    "            opt_gen.step()\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "#         if idx % 10 == 0:\n",
    "#             loop.set_postfix(\n",
    "#                 D_real=torch.sigmoid(D_real).mean().item(),\n",
    "#                 D_fake=torch.sigmoid(D_fake).mean().item(),\n",
    "#             )\n",
    "            \n",
    "    for x,y in val_loader :\n",
    "        x = x.float()/255\n",
    "        y = y.float()/255\n",
    "        x = x.to(Device)\n",
    "        y = y.to(Device)\n",
    "        img = gen(x).detach().numpy()[0]\n",
    "        img = np.moveaxis(img, 0, -1)\n",
    "        x = x.detach().numpy()[0]\n",
    "        x = np.moveaxis(x, 0, -1)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        plt.imshow(x)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in val_loader :\n",
    "    x = x.float()/255\n",
    "    y = y.float()/255\n",
    "    x = x.to(Device)\n",
    "    y = y.to(Device)\n",
    "    img = gen(x).detach().numpy()[0]\n",
    "    img = np.moveaxis(img, 0, -1)\n",
    "    x = x.detach().numpy()[0]\n",
    "    x = np.moveaxis(x, 0, -1)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    plt.imshow(x)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a0925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f900c785db5d6aace90a9a771392c78b459529dc57ca8760992166058dce648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
